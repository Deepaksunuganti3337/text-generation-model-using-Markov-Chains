# -*- coding: utf-8 -*-
"""festproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eIMy70AOwKD3J4JGbbgHtlBoOvNkNDpX
"""

import random
import string
import os
from collections import defaultdict, Counter
from nltk.translate.bleu_score import corpus_bleu
import matplotlib.pyplot as plt

# Function to clean and preprocess text
def clean_text(text):
    """Convert text to lowercase and remove punctuation."""
    text = text.lower()
    text = ''.join([char if char not in string.punctuation else ' ' for char in text])
    return text

# Function to build a Markov chain model with Kneser-Ney smoothing (a more advanced smoothing technique)
def build_markov_chain(text, n=2, smoothing=0.1):
    """
    Build a Markov chain model with Kneser-Ney smoothing.
    """
    markov_chain = defaultdict(Counter)  # Use Counter for automatic frequency counting
    word_count = Counter()

    words = text.split()

    # Create n-grams and store them
    for i in range(len(words) - n):
        ngram = tuple(words[i:i+n])
        next_word = words[i + n]

        # Store frequency of n-grams and their next words
        markov_chain[ngram][next_word] += 1
        word_count[ngram] += 1

    # Apply Kneser-Ney smoothing: smooth with the frequency of next words in the entire corpus
    for ngram in markov_chain:
        total_count = word_count[ngram] + smoothing * len(markov_chain[ngram])
        for word in markov_chain[ngram]:
            markov_chain[ngram][word] = (markov_chain[ngram][word] + smoothing) / total_count

    return markov_chain

# Function to generate text using the Markov chain with temperature sampling
def generate_text(markov_chain, ngram_size=2, length=50, seed=None, temperature=1.0):
    """
    Generate text using the Markov chain.
    - temperature: A value to control the randomness of the selection (higher -> more random)
    """
    if not seed:
        ngram = random.choice(list(markov_chain.keys()))
    else:
        ngram = tuple(seed.split())

    result = list(ngram)
    for _ in range(length - ngram_size):
        next_words = list(markov_chain[ngram].keys())
        next_word_probs = list(markov_chain[ngram].values())

        # Apply temperature to the probability distribution
        if temperature != 1.0:
            next_word_probs = [prob ** (1.0 / temperature) for prob in next_word_probs]
            total_prob = sum(next_word_probs)
            next_word_probs = [prob / total_prob for prob in next_word_probs]

        # Select the next word using the modified probability distribution
        next_word = random.choices(next_words, weights=next_word_probs)[0]
        result.append(next_word)

        # Update the n-gram to the last n-1 words
        ngram = tuple(result[-ngram_size:])

    return ' '.join(result)

# Function to load text from a file
def load_text_from_file(file_path):
    """Load and combine text from a single file."""
    combined_text = ""
    if os.path.exists(file_path):
        with open(file_path, 'r') as file:
            combined_text = file.read()
    else:
        print(f"Warning: File '{file_path}' not found.")
    return combined_text

# Function to select multiple random seeds from the text
def select_random_seeds(text, ngram_size, num_seeds=20):
    """
    Select multiple random seeds of length ngram_size from the cleaned text.
    """
    words = text.split()
    seeds = []

    for _ in range(num_seeds):
        random_index = random.randint(0, len(words) - ngram_size - 1)
        seed = ' '.join(words[random_index:random_index + ngram_size])
        seeds.append(seed)

    return seeds

# Function to evaluate BLEU score for generated text
def evaluate_bleu_score(reference_texts, generated_texts):
    """
    Evaluate BLEU score between generated texts and reference texts.
    """
    reference_corpus = [[text.split()] for text in reference_texts]  # Reference corpus
    generated_corpus = [text.split() for text in generated_texts]  # Generated corpus

    # Calculate BLEU score for the entire corpus
    score = corpus_bleu(reference_corpus, generated_corpus)
    return score

# Main code
if __name__ == "__main__":
    # Load a custom text dataset (replace this with your text file)
    text_file = '/content/sherlockholmes.txt'  # Path to your text file
    text = load_text_from_file(text_file)

    # Clean and preprocess the text
    cleaned_text = clean_text(text)

    # Set n-gram sizes and smoothing factor
    ngram_sizes = [2, 3, 4, 5]  # Bigrams, trigrams, 4-grams, and 5-grams
    smoothing = 0.1
    temperature = 1.0  # Control randomness of text generation

    # Store BLEU scores and text for each n-gram size
    bleu_scores = []
    generated_texts_all = []
    seeds_all = []

    # Evaluate for each n-gram size
    for ngram_size in ngram_sizes:
        print(f"Evaluating for {ngram_size}-grams...\n")

        # Build Markov Chain model with Kneser-Ney smoothing
        markov_chain = build_markov_chain(cleaned_text, n=ngram_size, smoothing=smoothing)

        # Select 20 random seeds from the text
        seeds = select_random_seeds(cleaned_text, ngram_size, num_seeds=20)
        seeds_all.append(seeds)
        print(f"Selected Seeds: {seeds}\n")

        # Generate text for each seed and calculate BLEU score
        generated_texts = []
        for seed in seeds:
            generated_text = generate_text(markov_chain, ngram_size=ngram_size, length=100, seed=seed, temperature=temperature)
            generated_texts.append(generated_text)

        # Calculate BLEU score
        bleu_score = evaluate_bleu_score(seeds, generated_texts)
        bleu_scores.append(bleu_score)
        generated_texts_all.append(generated_texts)

        # Display the generated text for the first few seeds
        print(f"Generated Texts for {ngram_size}-grams:")
        for seed, generated_text in zip(seeds[:5], generated_texts[:5]):  # Display first 5 for brevity
            print(f"Seed: {seed}\nGenerated Text: {generated_text}\n")

        print(f"BLEU Score for {ngram_size}-grams: {bleu_score:.4f}\n")

    # Plot the BLEU scores for each n-gram size
    plt.bar(ngram_sizes, bleu_scores)
    plt.title("BLEU Score for Different N-Gram Sizes")
    plt.xlabel("N-Gram Size")
    plt.ylabel("BLEU Score")
    plt.show()

import random
import string
import os
from collections import defaultdict, Counter
from nltk.translate.bleu_score import corpus_bleu
import matplotlib.pyplot as plt

# Function to clean and preprocess text
def clean_text(text):
    """Convert text to lowercase and remove punctuation."""
    text = text.lower()
    text = ''.join([char if char not in string.punctuation else ' ' for char in text])
    return text

# Function to build a Markov chain model with advanced smoothing
def build_markov_chain(text, n=2, smoothing=0.1):
    """
    Build a Markov chain model with Kneser-Ney smoothing or similar advanced smoothing.
    """
    markov_chain = defaultdict(Counter)
    word_count = Counter()

    words = text.split()

    # Create n-grams and store them
    for i in range(len(words) - n):
        ngram = tuple(words[i:i+n])
        next_word = words[i + n]

        markov_chain[ngram][next_word] += 1
        word_count[ngram] += 1

    # Apply advanced smoothing (Kneser-Ney or Good-Turing smoothing)
    for ngram in markov_chain:
        total_count = word_count[ngram] + smoothing * len(markov_chain[ngram])
        for word in markov_chain[ngram]:
            markov_chain[ngram][word] = (markov_chain[ngram][word] + smoothing) / total_count

    return markov_chain

# Function to generate text using the Markov chain with temperature control
def generate_text(markov_chain, ngram_size=2, length=100, seed=None, temperature=0.7):
    """Generate text using the Markov chain with temperature control for randomness."""
    if not seed:
        ngram = random.choice(list(markov_chain.keys()))
    else:
        ngram = tuple(seed.split())

    result = list(ngram)
    for _ in range(length - ngram_size):
        # Check if there are next words in the ngram
        if ngram not in markov_chain or not markov_chain[ngram]:
            print(f"Warning: No next word found for ngram {ngram}, skipping generation.")
            break

        next_words = list(markov_chain[ngram].keys())
        next_word_probs = list(markov_chain[ngram].values())

        # Apply temperature to adjust the probability distribution
        if temperature != 1.0:
            next_word_probs = [prob ** (1.0 / temperature) for prob in next_word_probs]
            total_prob = sum(next_word_probs)
            next_word_probs = [prob / total_prob for prob in next_word_probs]

        next_word = random.choices(next_words, weights=next_word_probs)[0]
        result.append(next_word)

        # Update the n-gram to the last n-1 words
        ngram = tuple(result[-ngram_size:])

    return ' '.join(result)

# Function to load text from a file
def load_text_from_file(file_path):
    """Load text from a single file."""
    combined_text = ""
    if os.path.exists(file_path):
        with open(file_path, 'r') as file:
            combined_text = file.read()
    else:
        print(f"Warning: File '{file_path}' not found.")
    return combined_text

# Function to select multiple random seeds from the text
def select_random_seeds(text, ngram_size, num_seeds=20):
    """Select random seeds from the text."""
    words = text.split()
    seeds = []

    for _ in range(num_seeds):
        random_index = random.randint(0, len(words) - ngram_size - 1)
        seed = ' '.join(words[random_index:random_index + ngram_size])
        seeds.append(seed)

    return seeds

# Function to evaluate BLEU score for generated text
def evaluate_bleu_score(reference_texts, generated_texts):
    """Evaluate BLEU score between generated and reference texts."""
    reference_corpus = [[text.split()] for text in reference_texts]  # Reference corpus
    generated_corpus = [text.split() for text in generated_texts]  # Generated corpus

    score = corpus_bleu(reference_corpus, generated_corpus)
    return score

# Main code
if __name__ == "__main__":
    # Load the text dataset
    text_file = '/content/sherlockholmes.txt'  # Path to your text file
    text = load_text_from_file(text_file)

    # Clean and preprocess the text
    cleaned_text = clean_text(text)

    # Define different n-gram sizes for testing
    ngram_sizes = [3, 4, 5, 6]  # Testing with larger n-grams (trigrams, 4-grams, etc.)
    smoothing = 0.1  # Smooth factor
    temperature = 0.7  # Temperature for sampling (controls randomness)

    bleu_scores = []
    generated_texts_all = []
    seeds_all = []

    for ngram_size in ngram_sizes:
        print(f"Evaluating {ngram_size}-gram model...\n")

        # Build the Markov Chain model with advanced smoothing
        markov_chain = build_markov_chain(cleaned_text, n=ngram_size, smoothing=smoothing)

        # Select random seeds from the text
        seeds = select_random_seeds(cleaned_text, ngram_size, num_seeds=20)
        seeds_all.append(seeds)
        print(f"Selected Seeds: {seeds}\n")

        # Generate text for each seed and calculate BLEU score
        generated_texts = []
        for seed in seeds:
            generated_text = generate_text(markov_chain, ngram_size=ngram_size, length=100, seed=seed, temperature=temperature)
            generated_texts.append(generated_text)

        # Calculate BLEU score
        bleu_score = evaluate_bleu_score(seeds, generated_texts)
        bleu_scores.append(bleu_score)
        generated_texts_all.append(generated_texts)

        # Display the generated text for the first few seeds
        print(f"Generated Texts for {ngram_size}-grams:")
        for seed, generated_text in zip(seeds[:5], generated_texts[:5]):  # Display first 5 for brevity
            print(f"Seed: {seed}\nGenerated Text: {generated_text}\n")

        print(f"BLEU Score for {ngram_size}-grams: {bleu_score:.4f}\n")

    # Plot the BLEU scores for each n-gram size
    plt.bar(ngram_sizes, bleu_scores)
    plt.title("BLEU Score for Different N-Gram Sizes")
    plt.xlabel("N-Gram Size")
    plt.ylabel("BLEU Score")
    plt.show()
    print(seeds)